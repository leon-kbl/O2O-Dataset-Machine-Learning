{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacking及增量学习"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User_id</th>\n",
       "      <th>Merchant_id</th>\n",
       "      <th>Coupon_id</th>\n",
       "      <th>Discount_rate</th>\n",
       "      <th>Distance</th>\n",
       "      <th>Date_received</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1439408</td>\n",
       "      <td>2632</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20160217.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1439408</td>\n",
       "      <td>4663</td>\n",
       "      <td>11002.0</td>\n",
       "      <td>150:20</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160528.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1439408</td>\n",
       "      <td>2632</td>\n",
       "      <td>8591.0</td>\n",
       "      <td>20:1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20160217.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1439408</td>\n",
       "      <td>2632</td>\n",
       "      <td>1078.0</td>\n",
       "      <td>20:1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20160319.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1439408</td>\n",
       "      <td>2632</td>\n",
       "      <td>8591.0</td>\n",
       "      <td>20:1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20160613.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   User_id  Merchant_id  Coupon_id Discount_rate  Distance  Date_received  \\\n",
       "0  1439408         2632        NaN           NaN       0.0            NaN   \n",
       "1  1439408         4663    11002.0        150:20       1.0     20160528.0   \n",
       "2  1439408         2632     8591.0          20:1       0.0     20160217.0   \n",
       "3  1439408         2632     1078.0          20:1       0.0     20160319.0   \n",
       "4  1439408         2632     8591.0          20:1       0.0     20160613.0   \n",
       "\n",
       "         Date  \n",
       "0  20160217.0  \n",
       "1         NaN  \n",
       "2         NaN  \n",
       "3         NaN  \n",
       "4         NaN  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('./ccf_offline_stage1_train-Copy1.csv', nrows = 200000)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 搭建两层Stacking模型，第一层模型由逻辑回归/随机森林/GBDT组成，第二层模型使用逻辑回归组合第一层模型。评价该Stacking模型，并与单模型质量对比"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ma-user/anaconda3/envs/XGBoost-Sklearn/lib/python3.6/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "df['Discount_rate']=df['Discount_rate'].fillna(0)\n",
    "df['Discount_rate_new']=df['Discount_rate'].apply(lambda x:x if ':' not in str(x) else ((float(x.split(':')[0])-float(x.split(':')[1]))/float(x.split(':')[0])))\n",
    "df['Discount_rate_new']=df['Discount_rate_new'].apply(lambda x:round(float(x),2))\n",
    "from sklearn.model_selection import train_test_split\n",
    "df['label']=df['Date'].apply(lambda x:1 if x==x else 0)\n",
    "y=df['label']\n",
    "X=df\n",
    "df['label']=df['Date'].apply(lambda x:1 if x==x else 0)\n",
    "y=df['label']\n",
    "selected_features=['Merchant_id','Coupon_id','Discount_rate_new','Distance']\n",
    "x_train,x_test,y_train,y_test=train_test_split(X.loc[:,selected_features].fillna(0),y,test_size=0.3,random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#组合模型\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import numpy as np\n",
    "\n",
    "clfs = [LogisticRegression(),\n",
    "       RandomForestClassifier(n_estimators=50, max_depth = 15, criterion='gini'),\n",
    "       GradientBoostingClassifier(n_estimators=500, max_depth=8, learning_rate=0.1)]\n",
    "\n",
    "skf = StratifiedKFold(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_stacking_train = np.zeros((x_train.shape[0], len(clfs)))   \n",
    "dataset_stacking_test = np.zeros((x_test.shape[0], len(clfs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.zeros((x_test.shape[0], len(clfs))) #(几行几列)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.zeros((x_test.shape[0],)) #(n列，1行)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val auc Score: 0.952832\n",
      "val auc Score: 0.985474\n",
      "val auc Score: 0.985126\n"
     ]
    }
   ],
   "source": [
    "#每个模型依次训练\n",
    "\n",
    "for i, clf in enumerate(clfs):\n",
    "    dataset_stacking_test_i = np.zeros((x_test.shape[0],))  \n",
    "    for j, (train_index, test_index) in enumerate(skf.split(x_train, y_train)):\n",
    "        X_train, Y_train, X_test, Y_test = x_train.iloc[train_index], y_train.iloc[train_index], x_train.iloc[test_index], y_train.iloc[test_index]\n",
    "        clf.fit(X_train, Y_train)\n",
    "        y_submission = clf.predict_proba(X_test)[:, 1]  #预测概率有两项，前一项为所有为0的概率，后一项为所有为1的概率\n",
    "        dataset_stacking_train[test_index, i] = y_submission #找出每个模型下对应的训练集下交叉选择的测试集\n",
    "        dataset_stacking_test_i = np.c_[dataset_stacking_test_i, clf.predict_proba(x_test)[:, 1]] #将np.c_行合并\n",
    "    dataset_stacking_test_i = np.delete(dataset_stacking_test_i, 0, axis=1) #删除掉0索引列\n",
    "    dataset_stacking_test[:, i] = dataset_stacking_test_i.mean(1) #得出每一列的平均值，返回一行多列\n",
    "    print(\"val auc Score: %f\" % roc_auc_score(y_test, dataset_stacking_test[:, i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression()\n",
    "clf.fit(dataset_stacking_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear stretch of predictions to [0,1]\n",
      "blend result\n",
      "val auc Score: 0.984639\n"
     ]
    }
   ],
   "source": [
    "y_submission = clf.predict_proba(dataset_stacking_test)[:,1]\n",
    "print(\"Linear stretch of predictions to [0,1]\")\n",
    "y_submission = (y_submission - y_submission.min()) / (y_submission.max() - y_submission.min())\n",
    "print(\"blend result\")\n",
    "print(\"val auc Score: %f\" % (roc_auc_score(y_test, y_submission)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression, SGDRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import log_loss, roc_auc_score, auc, roc_curve, f1_score\n",
    "import os\n",
    "os.system('pip install lightgbm')\n",
    "import lightgbm as lgb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#模型融合中使用到的单个模型\n",
    "rf_params = {'n_estimators':5,\n",
    "           'n_jobs' :-1,\n",
    "           'criterion': 'entropy'}\n",
    "\n",
    "lgb_params = {\n",
    "    'learning_rate':0.1,\n",
    "    'max_depth':4,\n",
    "    'objective':'binary',\n",
    "    'n_estimators':300\n",
    "}\n",
    "\n",
    "clfs = { LogisticRegression(),\n",
    "        RandomForestClassifier(**rf_params),\n",
    "        lgb.LGBMClassifier(**lgb_params)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''切分一部分数据作为测试集'''\n",
    "dataset_stacking_train = np.zeros((x_train.shape[0], len(clfs)))\n",
    "dataset_stacking_test = np.zeros((x_test.shape[0], len(clfs)))\n",
    "'''5折stacking'''\n",
    "n_folds = 5\n",
    "skf = StratifiedKFold(n_folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "Fold 0\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "val auc Score: 0.952236\n",
      "1 RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=5, n_jobs=-1, oob_score=False, random_state=None,\n",
      "            verbose=0, warm_start=False)\n",
      "Fold 0\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "val auc Score: 0.982133\n",
      "2 LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
      "        importance_type='split', learning_rate=0.1, max_depth=4,\n",
      "        min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
      "        n_estimators=300, n_jobs=-1, num_leaves=31, objective='binary',\n",
      "        random_state=None, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
      "        subsample=1.0, subsample_for_bin=200000, subsample_freq=0)\n",
      "Fold 0\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "val auc Score: 0.984684\n"
     ]
    }
   ],
   "source": [
    "for j, clf in enumerate(clfs):\n",
    "    '''依次训练各个单模型'''\n",
    "    print(j, clf)\n",
    "    dataset_stacking_test_j = np.zeros((x_test.shape[0], len(x_train)), dtype='float16')#默认data type float64总是遇到空间不足的问题\n",
    "    for i, (train_index, test_index) in enumerate(skf.split(x_train,y_train)):\n",
    "        '''使用第i个部分作为预测，剩余的部分来训练模型，获得其预测的输出作为第i部分的新特征。'''\n",
    "        print(\"Fold\",i)\n",
    "        fX_train, fy_train, fX_test, fy_test = x_train.iloc[train_index,:], y_train.iloc[train_index], x_train.iloc[test_index,:], y_train.iloc[test_index]\n",
    "        clf.fit(fX_train, fy_train)\n",
    "        y_submission = clf.predict_proba(fX_test)[:,1]\n",
    "        dataset_stacking_train[test_index,j] = y_submission\n",
    "        dataset_stacking_test_j[:,i] = clf.predict_proba(x_test)[:,1]\n",
    "    '''对于测试集，直接用这k个模型的预测值均值作为新的特征。'''\n",
    "    dataset_stacking_test[:, j] = dataset_stacking_test_j.mean(1)\n",
    "    print(\"val auc Score: %f\" % roc_auc_score(y_test, dataset_stacking_test[:, j]))\n",
    "    #问题出在cup内存不足，"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression()\n",
    "clf.fit(dataset_stacking_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear stretch of predictions to [0,1]\n",
      "blend result\n",
      "val auc Score: 0.985206\n"
     ]
    }
   ],
   "source": [
    "y_submission = clf.predict_proba(dataset_stacking_test)[:, 1]\n",
    "print(\"Linear stretch of predictions to [0,1]\")\n",
    "y_submission = (y_submission - y_submission.min()) / (y_submission.max() - y_submission.min())\n",
    "print(\"blend result\")\n",
    "print(\"val auc Score: %f\" % (roc_auc_score(y_test, y_submission)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 顺次使用每天的折扣券使用情况作为模型输入，使用逻辑回归增量学习每天的数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.1997173361737552 0.19270561634491312\n",
      "\t\t用SGD 进行预测得到的auc： 0.9616141622882236\n",
      "1 0.4703791915574348 0.4640943598970658\n",
      "\t\t用SGD 进行预测得到的auc： 0.9615008926086365\n",
      "2 0.5936525076545913 0.5878315759159289\n",
      "\t\t用SGD 进行预测得到的auc： 0.9614662023058832\n",
      "3 0.6602660172866648 0.6547581579663577\n",
      "\t\t用SGD 进行预测得到的auc： 0.961388518708937\n",
      "4 0.7001941464072234 0.6949222204037162\n",
      "\t\t用SGD 进行预测得到的auc： 0.9613346915915212\n",
      "5 0.7263010760014483 0.7212228372374424\n",
      "\t\t用SGD 进行预测得到的auc： 0.9613080212824937\n",
      "6 0.7440615505526917 0.7391307155312152\n",
      "\t\t用SGD 进行预测得到的auc： 0.9612775554503644\n",
      "7 0.7568537948259063 0.7520423892363454\n",
      "\t\t用SGD 进行预测得到的auc： 0.9612242338782422\n",
      "8 0.7664444181312011 0.7617443885700022\n",
      "\t\t用SGD 进行预测得到的auc： 0.9612115490802152\n",
      "9 0.7738576969779756 0.7692477574872236\n",
      "\t\t用SGD 进行预测得到的auc： 0.9612344447752619\n",
      "10 0.7796642493550723 0.7751208830468006\n",
      "\t\t用SGD 进行预测得到的auc： 0.961187824473065\n",
      "11 0.7843730689548587 0.7798891246985277\n",
      "\t\t用SGD 进行预测得到的auc： 0.9611887823592543\n",
      "12 0.7883730850951647 0.7839481776279451\n",
      "\t\t用SGD 进行预测得到的auc： 0.9611841214883522\n",
      "13 0.7917029937069306 0.787324581574611\n",
      "\t\t用SGD 进行预测得到的auc： 0.9611761791275031\n",
      "14 0.7946041374053767 0.7902783988750631\n",
      "\t\t用SGD 进行预测得到的auc： 0.9612052428063669\n",
      "15 0.7970699193018658 0.7927845668312317\n",
      "\t\t用SGD 进行预测得到的auc： 0.9612517295800157\n",
      "16 0.7992165348371516 0.7949633815214403\n",
      "\t\t用SGD 进行预测得到的auc： 0.9612743704322056\n",
      "17 0.8011334485736946 0.7969119672751706\n",
      "\t\t用SGD 进行预测得到的auc： 0.9612809518369692\n",
      "18 0.8028742347210878 0.7986854654007107\n",
      "\t\t用SGD 进行预测得到的auc： 0.9613125993449939\n",
      "19 0.8043594216283965 0.8001889252923899\n",
      "\t\t用SGD 进行预测得到的auc： 0.9613053138617931\n",
      "20 0.8057402184644253 0.8015920154672012\n",
      "\t\t用SGD 进行预测得到的auc： 0.9613088178993202\n",
      "21 0.8070180657285259 0.8028948394616284\n",
      "\t\t用SGD 进行预测得到的auc： 0.9613406494490182\n",
      "22 0.8081521132332067 0.8040468110839294\n",
      "\t\t用SGD 进行预测得到的auc： 0.961430907294775\n",
      "23 0.8092194283026962 0.8051349748343413\n",
      "\t\t用SGD 进行预测得到的auc： 0.9614677690408475\n",
      "24 0.8101584071775276 0.8060808792342271\n",
      "\t\t用SGD 进行预测得到的auc： 0.9614687101583353\n",
      "25 0.8110299272364939 0.80696477757716\n",
      "\t\t用SGD 进行预测得到的auc： 0.9615329787941704\n",
      "26 0.8118484020306198 0.8077972836960949\n",
      "\t\t用SGD 进行预测得到的auc： 0.9615734377372225\n",
      "27 0.8125961787099713 0.808555209911161\n",
      "\t\t用SGD 进行预测得到的auc： 0.9616180437250426\n",
      "28 0.8133042868814563 0.8092760712851725\n",
      "\t\t用SGD 进行预测得到的auc： 0.9616576590575001\n",
      "29 0.8139214101473485 0.8099027835959892\n",
      "\t\t用SGD 进行预测得到的auc： 0.9616847984761243\n",
      "30 0.8145369451114794 0.8105284714036267\n",
      "\t\t用SGD 进行预测得到的auc： 0.9617022681506354\n",
      "31 0.8151105850641456 0.8111110622830513\n",
      "\t\t用SGD 进行预测得到的auc： 0.9617353428614672\n",
      "32 0.8156111263669594 0.8116181276193114\n",
      "\t\t用SGD 进行预测得到的auc： 0.9617707598079474\n",
      "33 0.8161230610353126 0.812146763015772\n",
      "\t\t用SGD 进行预测得到的auc： 0.9618331072888578\n",
      "34 0.8165806937247494 0.8126138922295432\n",
      "\t\t用SGD 进行预测得到的auc： 0.9618722239077149\n",
      "35 0.8169981690491221 0.8130389724625985\n",
      "\t\t用SGD 进行预测得到的auc： 0.9618834661833806\n",
      "36 0.8173854682395783 0.8134296107576116\n",
      "\t\t用SGD 进行预测得到的auc： 0.9619281864467953\n",
      "37 0.8177250845199683 0.8137725341936226\n",
      "\t\t用SGD 进行预测得到的auc： 0.9619599192474739\n",
      "38 0.818059869030723 0.8141119899175877\n",
      "\t\t用SGD 进行预测得到的auc： 0.962013959803546\n",
      "39 0.8183878518717269 0.8144498571223647\n",
      "\t\t用SGD 进行预测得到的auc： 0.9620566019901144\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(x_train)\n",
    "X_train_scaled = scaler.transform(x_train)\n",
    "X_test_scaled = scaler.transform(x_test)\n",
    "reg = SGDRegressor()\n",
    "\n",
    "#没有用时间增量，只是选取了X_train的部分数据试了一下增量学习\n",
    "for _ in range(40):\n",
    "    idx_list = list(range(len(X_train_scaled)))\n",
    "    reg.partial_fit(X_train_scaled[idx_list[:100],:],y_train.values[idx_list[:100]])\n",
    "    print(_,reg.score(X_train_scaled, y_train), reg.score(X_test_scaled, y_test))\n",
    "    print('\\t\\t用SGD 进行预测得到的auc：',roc_auc_score(y_train,reg.predict(X_train_scaled)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 正向神经网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User_id</th>\n",
       "      <th>Merchant_id</th>\n",
       "      <th>Coupon_id</th>\n",
       "      <th>Discount_rate</th>\n",
       "      <th>Distance</th>\n",
       "      <th>Date_received</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1439408</td>\n",
       "      <td>2632</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20160217.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1439408</td>\n",
       "      <td>4663</td>\n",
       "      <td>11002.0</td>\n",
       "      <td>150:20</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160528.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1439408</td>\n",
       "      <td>2632</td>\n",
       "      <td>8591.0</td>\n",
       "      <td>20:1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20160217.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1439408</td>\n",
       "      <td>2632</td>\n",
       "      <td>1078.0</td>\n",
       "      <td>20:1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20160319.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1439408</td>\n",
       "      <td>2632</td>\n",
       "      <td>8591.0</td>\n",
       "      <td>20:1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20160613.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   User_id  Merchant_id  Coupon_id Discount_rate  Distance  Date_received  \\\n",
       "0  1439408         2632        NaN           NaN       0.0            NaN   \n",
       "1  1439408         4663    11002.0        150:20       1.0     20160528.0   \n",
       "2  1439408         2632     8591.0          20:1       0.0     20160217.0   \n",
       "3  1439408         2632     1078.0          20:1       0.0     20160319.0   \n",
       "4  1439408         2632     8591.0          20:1       0.0     20160613.0   \n",
       "\n",
       "         Date  \n",
       "0  20160217.0  \n",
       "1         NaN  \n",
       "2         NaN  \n",
       "3         NaN  \n",
       "4         NaN  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('./ccf_offline_stage1_train.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用Pytorch或者Tensorflow，搭建三层神经网络模型，对用户的促销券使用情况建模，并在随机切分的测试集上查看训练准确率，并调优模型并和XGBoost模型结果对比\n",
    "#### 该模型质量劣于XGBoost模型是正常情况"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import argparse\n",
    "import torch\n",
    "import torch.utils.data\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torchvision import datasets, transforms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User_id</th>\n",
       "      <th>Merchant_id</th>\n",
       "      <th>Coupon_id</th>\n",
       "      <th>Discount_rate</th>\n",
       "      <th>Distance</th>\n",
       "      <th>Date_received</th>\n",
       "      <th>Date</th>\n",
       "      <th>Discount_rate_new</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>382193</th>\n",
       "      <td>2462193</td>\n",
       "      <td>5341</td>\n",
       "      <td>7751.0</td>\n",
       "      <td>50:10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20160131.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1250747</th>\n",
       "      <td>3071464</td>\n",
       "      <td>6485</td>\n",
       "      <td>2079.0</td>\n",
       "      <td>30:5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20160524.0</td>\n",
       "      <td>20160529.0</td>\n",
       "      <td>0.83</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>580400</th>\n",
       "      <td>1104814</td>\n",
       "      <td>5755</td>\n",
       "      <td>13465.0</td>\n",
       "      <td>100:20</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160416.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1356874</th>\n",
       "      <td>1898571</td>\n",
       "      <td>3561</td>\n",
       "      <td>14006.0</td>\n",
       "      <td>10:1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20160115.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78932</th>\n",
       "      <td>1197041</td>\n",
       "      <td>2247</td>\n",
       "      <td>98.0</td>\n",
       "      <td>30:5</td>\n",
       "      <td>10.0</td>\n",
       "      <td>20160522.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         User_id  Merchant_id  Coupon_id Discount_rate  Distance  \\\n",
       "382193   2462193         5341     7751.0         50:10       0.0   \n",
       "1250747  3071464         6485     2079.0          30:5       0.0   \n",
       "580400   1104814         5755    13465.0        100:20       1.0   \n",
       "1356874  1898571         3561    14006.0          10:1       0.0   \n",
       "78932    1197041         2247       98.0          30:5      10.0   \n",
       "\n",
       "         Date_received        Date  Discount_rate_new  label  \n",
       "382193      20160131.0         NaN               0.80      0  \n",
       "1250747     20160524.0  20160529.0               0.83      1  \n",
       "580400      20160416.0         NaN               0.80      0  \n",
       "1356874     20160115.0         NaN               0.90      0  \n",
       "78932       20160522.0         NaN               0.83      0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Discount_rate']=df['Discount_rate'].fillna(0)\n",
    "df['Discount_rate_new']=df['Discount_rate'].apply(lambda x:x if ':' not in str(x) else ((float(x.split(':')[0])-float(x.split(':')[1]))/float(x.split(':')[0])))\n",
    "df['Discount_rate_new']=df['Discount_rate_new'].apply(lambda x:round(float(x),2))\n",
    "from sklearn.model_selection import train_test_split\n",
    "df['label']=df['Date'].apply(lambda x:1 if x==x else 0)\n",
    "y=df['label']\n",
    "from sklearn.model_selection import train_test_split\n",
    "X=df\n",
    "df['label']=df['Date'].apply(lambda x:1 if x==x else 0)\n",
    "y=df['label']\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3,random_state=0)\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "feature=['Merchant_id','Coupon_id','Distance','Discount_rate_new']\n",
    "scaler=StandardScaler()\n",
    "scaler.fit(X_train.loc[:,feature])\n",
    "X_train_scaler=pd.DataFrame(scaler.transform(X_train.loc[:,feature]),columns=feature)\n",
    "X_train_scaler=X_train_scaler.fillna(X_train_scaler.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Merchant_id</th>\n",
       "      <th>Coupon_id</th>\n",
       "      <th>Distance</th>\n",
       "      <th>Discount_rate_new</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.042725</td>\n",
       "      <td>-0.000621</td>\n",
       "      <td>-0.390638</td>\n",
       "      <td>-1.207849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.983392</td>\n",
       "      <td>0.775011</td>\n",
       "      <td>2.193110</td>\n",
       "      <td>0.939493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.013267</td>\n",
       "      <td>-0.422319</td>\n",
       "      <td>-0.677721</td>\n",
       "      <td>0.820196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.389114</td>\n",
       "      <td>-0.000621</td>\n",
       "      <td>1.044778</td>\n",
       "      <td>-1.207849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.221021</td>\n",
       "      <td>-0.000621</td>\n",
       "      <td>-0.677721</td>\n",
       "      <td>-1.207849</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Merchant_id  Coupon_id  Distance  Discount_rate_new\n",
       "0     0.042725  -0.000621 -0.390638          -1.207849\n",
       "1     0.983392   0.775011  2.193110           0.939493\n",
       "2    -1.013267  -0.422319 -0.677721           0.820196\n",
       "3     0.389114  -0.000621  1.044778          -1.207849\n",
       "4     1.221021  -0.000621 -0.677721          -1.207849"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_scaler=pd.DataFrame(scaler.transform(X_test.loc[:,feature]),columns=feature)\n",
    "X_test_scaler=X_test_scaler.fillna(X_test_scaler.mean())\n",
    "X_test_scaler.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Torch_Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.data = df.values\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n",
    "    \n",
    "    \n",
    "X_train_scaler['label']=y_train.values    \n",
    "X_test_scaler['label']=y_test.values\n",
    "\n",
    "trainset = Torch_Dataset(X_train_scaler)\n",
    "testset = Torch_Dataset(X_test_scaler)\n",
    "\n",
    "batch_size = 10000\n",
    "kwargs = {'num_workers': 0, 'pin_memory': True}\n",
    "train_loader = torch.utils.data.DataLoader(trainset, batch_size = batch_size, shuffle = True, **kwargs)\n",
    "test_loader = torch.utils.data.DataLoader(testset, batch_size = batch_size, shuffle = True, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class o2o_nn(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(o2o_nn, self).__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(4,3)\n",
    "        self.fc2 = nn.Linear(3,3)\n",
    "        self.fc3 = nn.Linear(3,1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h1 = self.relu(self.fc1(x))\n",
    "        h1 = self.dropout(h1)\n",
    "        h2 = self.relu(self.fc2(h1))\n",
    "        h2 = self.dropout(h2)\n",
    "        h3 = self.relu(self.fc3(h2))\n",
    "        h3 = self.dropout(h3)\n",
    "        return self.sigmoid(h3)\n",
    "model =o2o_nn()\n",
    "model = model.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = nn.BCELoss()\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for batch_idx, data in enumerate(train_loader):\n",
    "        feature = data[:,:-1]\n",
    "        label = data[:,-1]\n",
    "        data = Variable(feature)\n",
    "        optimizer.zero_grad()\n",
    "        label_pred = model(feature.float())\n",
    "        loss = loss_function(label_pred.float(), label.view(-1,1).float())\n",
    "        loss.backward()\n",
    "        train_loss += loss.data\n",
    "        optimizer.step()\n",
    "        if batch_idx % 10 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader),\n",
    "                loss.data / len(data)))       \n",
    "\n",
    "    print('====> Epoch: {} Average loss: {:.4f}'.format(\n",
    "          epoch, train_loss / len(train_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/1228418 (0%)]\tLoss: 0.000069\n",
      "Train Epoch: 1 [100000/1228418 (8%)]\tLoss: 0.000069\n",
      "Train Epoch: 1 [200000/1228418 (16%)]\tLoss: 0.000069\n",
      "Train Epoch: 1 [300000/1228418 (24%)]\tLoss: 0.000069\n",
      "Train Epoch: 1 [400000/1228418 (33%)]\tLoss: 0.000069\n",
      "Train Epoch: 1 [500000/1228418 (41%)]\tLoss: 0.000069\n",
      "Train Epoch: 1 [600000/1228418 (49%)]\tLoss: 0.000069\n",
      "Train Epoch: 1 [700000/1228418 (57%)]\tLoss: 0.000069\n",
      "Train Epoch: 1 [800000/1228418 (65%)]\tLoss: 0.000068\n",
      "Train Epoch: 1 [900000/1228418 (73%)]\tLoss: 0.000068\n",
      "Train Epoch: 1 [1000000/1228418 (81%)]\tLoss: 0.000068\n",
      "Train Epoch: 1 [1100000/1228418 (89%)]\tLoss: 0.000068\n",
      "Train Epoch: 1 [1200000/1228418 (98%)]\tLoss: 0.000068\n",
      "====> Epoch: 1 Average loss: 0.0001\n",
      "Train Epoch: 2 [0/1228418 (0%)]\tLoss: 0.000067\n",
      "Train Epoch: 2 [100000/1228418 (8%)]\tLoss: 0.000067\n",
      "Train Epoch: 2 [200000/1228418 (16%)]\tLoss: 0.000067\n",
      "Train Epoch: 2 [300000/1228418 (24%)]\tLoss: 0.000067\n",
      "Train Epoch: 2 [400000/1228418 (33%)]\tLoss: 0.000067\n",
      "Train Epoch: 2 [500000/1228418 (41%)]\tLoss: 0.000066\n",
      "Train Epoch: 2 [600000/1228418 (49%)]\tLoss: 0.000066\n",
      "Train Epoch: 2 [700000/1228418 (57%)]\tLoss: 0.000066\n",
      "Train Epoch: 2 [800000/1228418 (65%)]\tLoss: 0.000066\n",
      "Train Epoch: 2 [900000/1228418 (73%)]\tLoss: 0.000065\n",
      "Train Epoch: 2 [1000000/1228418 (81%)]\tLoss: 0.000065\n",
      "Train Epoch: 2 [1100000/1228418 (89%)]\tLoss: 0.000065\n",
      "Train Epoch: 2 [1200000/1228418 (98%)]\tLoss: 0.000065\n",
      "====> Epoch: 2 Average loss: 0.0001\n",
      "Train Epoch: 3 [0/1228418 (0%)]\tLoss: 0.000065\n",
      "Train Epoch: 3 [100000/1228418 (8%)]\tLoss: 0.000064\n",
      "Train Epoch: 3 [200000/1228418 (16%)]\tLoss: 0.000065\n",
      "Train Epoch: 3 [300000/1228418 (24%)]\tLoss: 0.000065\n",
      "Train Epoch: 3 [400000/1228418 (33%)]\tLoss: 0.000064\n",
      "Train Epoch: 3 [500000/1228418 (41%)]\tLoss: 0.000064\n",
      "Train Epoch: 3 [600000/1228418 (49%)]\tLoss: 0.000064\n",
      "Train Epoch: 3 [700000/1228418 (57%)]\tLoss: 0.000064\n",
      "Train Epoch: 3 [800000/1228418 (65%)]\tLoss: 0.000064\n",
      "Train Epoch: 3 [900000/1228418 (73%)]\tLoss: 0.000064\n",
      "Train Epoch: 3 [1000000/1228418 (81%)]\tLoss: 0.000064\n",
      "Train Epoch: 3 [1100000/1228418 (89%)]\tLoss: 0.000064\n",
      "Train Epoch: 3 [1200000/1228418 (98%)]\tLoss: 0.000064\n",
      "====> Epoch: 3 Average loss: 0.0001\n",
      "Train Epoch: 4 [0/1228418 (0%)]\tLoss: 0.000064\n",
      "Train Epoch: 4 [100000/1228418 (8%)]\tLoss: 0.000064\n",
      "Train Epoch: 4 [200000/1228418 (16%)]\tLoss: 0.000063\n",
      "Train Epoch: 4 [300000/1228418 (24%)]\tLoss: 0.000064\n",
      "Train Epoch: 4 [400000/1228418 (33%)]\tLoss: 0.000063\n",
      "Train Epoch: 4 [500000/1228418 (41%)]\tLoss: 0.000064\n",
      "Train Epoch: 4 [600000/1228418 (49%)]\tLoss: 0.000064\n",
      "Train Epoch: 4 [700000/1228418 (57%)]\tLoss: 0.000064\n",
      "Train Epoch: 4 [800000/1228418 (65%)]\tLoss: 0.000063\n",
      "Train Epoch: 4 [900000/1228418 (73%)]\tLoss: 0.000063\n",
      "Train Epoch: 4 [1000000/1228418 (81%)]\tLoss: 0.000063\n",
      "Train Epoch: 4 [1100000/1228418 (89%)]\tLoss: 0.000063\n",
      "Train Epoch: 4 [1200000/1228418 (98%)]\tLoss: 0.000063\n",
      "====> Epoch: 4 Average loss: 0.0001\n",
      "Train Epoch: 5 [0/1228418 (0%)]\tLoss: 0.000063\n",
      "Train Epoch: 5 [100000/1228418 (8%)]\tLoss: 0.000063\n",
      "Train Epoch: 5 [200000/1228418 (16%)]\tLoss: 0.000063\n",
      "Train Epoch: 5 [300000/1228418 (24%)]\tLoss: 0.000063\n",
      "Train Epoch: 5 [400000/1228418 (33%)]\tLoss: 0.000063\n",
      "Train Epoch: 5 [500000/1228418 (41%)]\tLoss: 0.000063\n",
      "Train Epoch: 5 [600000/1228418 (49%)]\tLoss: 0.000063\n",
      "Train Epoch: 5 [700000/1228418 (57%)]\tLoss: 0.000063\n",
      "Train Epoch: 5 [800000/1228418 (65%)]\tLoss: 0.000063\n",
      "Train Epoch: 5 [900000/1228418 (73%)]\tLoss: 0.000063\n",
      "Train Epoch: 5 [1000000/1228418 (81%)]\tLoss: 0.000063\n",
      "Train Epoch: 5 [1100000/1228418 (89%)]\tLoss: 0.000064\n",
      "Train Epoch: 5 [1200000/1228418 (98%)]\tLoss: 0.000063\n",
      "====> Epoch: 5 Average loss: 0.0001\n",
      "Train Epoch: 6 [0/1228418 (0%)]\tLoss: 0.000063\n",
      "Train Epoch: 6 [100000/1228418 (8%)]\tLoss: 0.000063\n",
      "Train Epoch: 6 [200000/1228418 (16%)]\tLoss: 0.000063\n",
      "Train Epoch: 6 [300000/1228418 (24%)]\tLoss: 0.000063\n",
      "Train Epoch: 6 [400000/1228418 (33%)]\tLoss: 0.000063\n",
      "Train Epoch: 6 [500000/1228418 (41%)]\tLoss: 0.000063\n",
      "Train Epoch: 6 [600000/1228418 (49%)]\tLoss: 0.000063\n",
      "Train Epoch: 6 [700000/1228418 (57%)]\tLoss: 0.000063\n",
      "Train Epoch: 6 [800000/1228418 (65%)]\tLoss: 0.000063\n",
      "Train Epoch: 6 [900000/1228418 (73%)]\tLoss: 0.000063\n",
      "Train Epoch: 6 [1000000/1228418 (81%)]\tLoss: 0.000063\n",
      "Train Epoch: 6 [1100000/1228418 (89%)]\tLoss: 0.000063\n",
      "Train Epoch: 6 [1200000/1228418 (98%)]\tLoss: 0.000063\n",
      "====> Epoch: 6 Average loss: 0.0001\n",
      "Train Epoch: 7 [0/1228418 (0%)]\tLoss: 0.000063\n",
      "Train Epoch: 7 [100000/1228418 (8%)]\tLoss: 0.000063\n",
      "Train Epoch: 7 [200000/1228418 (16%)]\tLoss: 0.000064\n",
      "Train Epoch: 7 [300000/1228418 (24%)]\tLoss: 0.000063\n",
      "Train Epoch: 7 [400000/1228418 (33%)]\tLoss: 0.000063\n",
      "Train Epoch: 7 [500000/1228418 (41%)]\tLoss: 0.000063\n",
      "Train Epoch: 7 [600000/1228418 (49%)]\tLoss: 0.000063\n",
      "Train Epoch: 7 [700000/1228418 (57%)]\tLoss: 0.000063\n",
      "Train Epoch: 7 [800000/1228418 (65%)]\tLoss: 0.000063\n",
      "Train Epoch: 7 [900000/1228418 (73%)]\tLoss: 0.000063\n",
      "Train Epoch: 7 [1000000/1228418 (81%)]\tLoss: 0.000063\n",
      "Train Epoch: 7 [1100000/1228418 (89%)]\tLoss: 0.000063\n",
      "Train Epoch: 7 [1200000/1228418 (98%)]\tLoss: 0.000063\n",
      "====> Epoch: 7 Average loss: 0.0001\n",
      "Train Epoch: 8 [0/1228418 (0%)]\tLoss: 0.000063\n",
      "Train Epoch: 8 [100000/1228418 (8%)]\tLoss: 0.000063\n",
      "Train Epoch: 8 [200000/1228418 (16%)]\tLoss: 0.000063\n",
      "Train Epoch: 8 [300000/1228418 (24%)]\tLoss: 0.000063\n",
      "Train Epoch: 8 [400000/1228418 (33%)]\tLoss: 0.000063\n",
      "Train Epoch: 8 [500000/1228418 (41%)]\tLoss: 0.000063\n",
      "Train Epoch: 8 [600000/1228418 (49%)]\tLoss: 0.000063\n",
      "Train Epoch: 8 [700000/1228418 (57%)]\tLoss: 0.000063\n",
      "Train Epoch: 8 [800000/1228418 (65%)]\tLoss: 0.000063\n",
      "Train Epoch: 8 [900000/1228418 (73%)]\tLoss: 0.000063\n",
      "Train Epoch: 8 [1000000/1228418 (81%)]\tLoss: 0.000063\n",
      "Train Epoch: 8 [1100000/1228418 (89%)]\tLoss: 0.000063\n",
      "Train Epoch: 8 [1200000/1228418 (98%)]\tLoss: 0.000063\n",
      "====> Epoch: 8 Average loss: 0.0001\n",
      "Train Epoch: 9 [0/1228418 (0%)]\tLoss: 0.000063\n",
      "Train Epoch: 9 [100000/1228418 (8%)]\tLoss: 0.000063\n",
      "Train Epoch: 9 [200000/1228418 (16%)]\tLoss: 0.000063\n",
      "Train Epoch: 9 [300000/1228418 (24%)]\tLoss: 0.000063\n",
      "Train Epoch: 9 [400000/1228418 (33%)]\tLoss: 0.000063\n",
      "Train Epoch: 9 [500000/1228418 (41%)]\tLoss: 0.000063\n",
      "Train Epoch: 9 [600000/1228418 (49%)]\tLoss: 0.000063\n",
      "Train Epoch: 9 [700000/1228418 (57%)]\tLoss: 0.000063\n",
      "Train Epoch: 9 [800000/1228418 (65%)]\tLoss: 0.000063\n",
      "Train Epoch: 9 [900000/1228418 (73%)]\tLoss: 0.000063\n",
      "Train Epoch: 9 [1000000/1228418 (81%)]\tLoss: 0.000063\n",
      "Train Epoch: 9 [1100000/1228418 (89%)]\tLoss: 0.000063\n",
      "Train Epoch: 9 [1200000/1228418 (98%)]\tLoss: 0.000063\n",
      "====> Epoch: 9 Average loss: 0.0001\n",
      "Train Epoch: 10 [0/1228418 (0%)]\tLoss: 0.000063\n",
      "Train Epoch: 10 [100000/1228418 (8%)]\tLoss: 0.000063\n",
      "Train Epoch: 10 [200000/1228418 (16%)]\tLoss: 0.000063\n",
      "Train Epoch: 10 [300000/1228418 (24%)]\tLoss: 0.000063\n",
      "Train Epoch: 10 [400000/1228418 (33%)]\tLoss: 0.000063\n",
      "Train Epoch: 10 [500000/1228418 (41%)]\tLoss: 0.000063\n",
      "Train Epoch: 10 [600000/1228418 (49%)]\tLoss: 0.000063\n",
      "Train Epoch: 10 [700000/1228418 (57%)]\tLoss: 0.000063\n",
      "Train Epoch: 10 [800000/1228418 (65%)]\tLoss: 0.000063\n",
      "Train Epoch: 10 [900000/1228418 (73%)]\tLoss: 0.000063\n",
      "Train Epoch: 10 [1000000/1228418 (81%)]\tLoss: 0.000063\n",
      "Train Epoch: 10 [1100000/1228418 (89%)]\tLoss: 0.000063\n",
      "Train Epoch: 10 [1200000/1228418 (98%)]\tLoss: 0.000063\n",
      "====> Epoch: 10 Average loss: 0.0001\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 10\n",
    "for epoch in range(1,EPOCHS+1):\n",
    "    train(epoch)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "test_loss = 0\n",
    "y_tests = []\n",
    "y_preds = []\n",
    "for data in test_loader:\n",
    "    pred_list = []\n",
    "    feature = data[:,:-1]\n",
    "    label = data[:,-1]\n",
    "\n",
    "    label_pred = model(feature.float())\n",
    "    y_preds += label_pred.detach().numpy().ravel().tolist()\n",
    "    y_tests += label.numpy().ravel().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9520554687350172"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "roc_auc_score(y_tests, y_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9520586794544563\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "df=pd.read_csv('ccf_offline_stage1_train.csv')\n",
    "df['Discount_rate']=df['Discount_rate'].fillna(0)\n",
    "df['Discount_rate_new']=df['Discount_rate'].apply(lambda x:x if ':' not in str(x) else ((float(x.split(':')[0])-float(x.split(':')[1]))/float(x.split(':')[0])))\n",
    "df['Discount_rate_new']=df['Discount_rate_new'].apply(lambda x:round(float(x),2))\n",
    "from sklearn.model_selection import train_test_split\n",
    "df['label']=df['Date'].apply(lambda x:1 if x==x else 0)\n",
    "y=df['label']\n",
    "from sklearn.model_selection import train_test_split\n",
    "X=df\n",
    "df['label']=df['Date'].apply(lambda x:1 if x==x else 0)\n",
    "y=df['label']\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3,random_state=0)\n",
    "feature=['Merchant_id','Coupon_id','Distance','Discount_rate_new']\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "feature=['Merchant_id','Coupon_id','Distance','Discount_rate_new']\n",
    "scaler=StandardScaler()\n",
    "scaler.fit(X_train.loc[:,feature])\n",
    "X_train_scaler=pd.DataFrame(scaler.transform(X_train.loc[:,feature]),columns=feature)\n",
    "X_train_scaler=X_train_scaler.fillna(X_train_scaler.mean())\n",
    "X_test_scaler=pd.DataFrame(scaler.transform(X_test.loc[:,feature]),columns=feature)\n",
    "X_test_scaler=X_test_scaler.fillna(X_test_scaler.mean())\n",
    "test_data=xgb.DMatrix(X_test_scaler.loc[:,feature].values,label=y_test)\n",
    "xgb_params={\n",
    "    'eta':0.3,\n",
    "    'silent':True,\n",
    "    'objective':'multi:softprob',\n",
    "    'num_class':3,\n",
    "    'max_depth':3\n",
    "}\n",
    "num_round=20\n",
    "model=xgb.train(xgb_params,xgb.DMatrix(X_train_scaler.loc[:,feature].values,label=y_train),num_round)\n",
    "test_pre=model.predict(test_data)\n",
    "test_pre_1=np.asarray([np.argmax(row) for row in test_pre])\n",
    "print(roc_auc_score(y_test,test_pre_1,average='macro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这次的作业就到这里了！祝大家学习进步！\n",
    "![image alt <](http://5b0988e595225.cdn.sohucs.com/images/20190420/1d1070881fd540db817b2a3bdd967f37.gif)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
